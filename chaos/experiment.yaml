# AI Integration Service - Chaos Engineering Experiments
# Generated by SRE Coach AI Assistant

experiments:
  - name: "dependency-failure-circuit-breaker"
    description: "Test circuit breaker behavior when AI Registry service fails"
    failure_to_inject: "Stop AI Registry service container for controlled period"
    duration: "10 minutes"
    target_service: "ai-registry-service"
    injection_method: "container_stop"
    
    metrics_to_watch:
      - circuit_breaker_state: "Should transition from CLOSED -> OPEN"
      - error_rate: "Should remain < 5% due to circuit breaker"
      - p95_latency: "Should stay < 400ms for non-registry requests"
      - fallback_success_rate: "Should maintain > 90% for other services"
    
    abort_conditions:
      - overall_error_rate: "> 10%"
      - p95_latency: "> 600ms"
      - healthy_services_down: "> 1"
      - experiment_duration: "> 15 minutes"
    
    expected_behavior:
      - "Circuit breaker opens after 5 failed requests"
      - "Requests to AI Registry return 503 with circuit breaker message"
      - "Other AI services (Model Performance, Guardrail) remain functional"
      - "System recovers when AI Registry service is restored"
    
    safety_measures:
      - "Run in staging environment only"
      - "Monitor all services continuously"
      - "Automated rollback after 10 minutes"
      - "Manual abort capability"

  - name: "cpu-stress-autoscaling"
    description: "Test system behavior under high CPU load"
    failure_to_inject: "Generate CPU load to 80-90% on gateway container"
    duration: "8 minutes"
    target_service: "ai-integration-service"
    injection_method: "cpu_stress"
    
    metrics_to_watch:
      - cpu_utilization: "Should reach 80-90% then stabilize or scale"
      - p95_latency: "May increase but should stay < 500ms"
      - error_rate: "Should remain < 2%"
      - memory_usage: "Should remain stable"
      - request_queue_depth: "Monitor for backlog"
    
    abort_conditions:
      - error_rate: "> 5%"
      - p95_latency: "> 800ms"
      - memory_usage: "> 90%"
      - service_unresponsive: "> 30 seconds"
    
    expected_behavior:
      - "Increased response times but within acceptable limits"
      - "Request queuing may occur but should drain"
      - "No service crashes or memory leaks"
      - "System recovers when CPU stress is removed"
    
    safety_measures:
      - "Gradual CPU increase to target level"
      - "Monitor memory to prevent OOM"
      - "Immediate stress removal on abort conditions"
      - "Container restart capability ready"

  - name: "network-latency-injection"
    description: "Test timeout and retry behavior with network delays"
    failure_to_inject: "Add 200-400ms latency to downstream AI services"
    duration: "12 minutes"
    target_service: "network_between_services"
    injection_method: "network_delay"
    
    metrics_to_watch:
      - p95_latency: "Should increase proportionally to injected delay"
      - timeout_rate: "Monitor for timeout errors"
      - retry_attempts: "Should see retry behavior"
      - circuit_breaker_state: "May transition if timeouts exceed threshold"
      - end_to_end_success_rate: "Should remain > 95%"
    
    abort_conditions:
      - error_rate: "> 3%"
      - p95_latency: "> 1000ms"
      - timeout_rate: "> 10%"
      - all_circuit_breakers_open: "true"
    
    expected_behavior:
      - "Increased latency but successful request completion"
      - "Retry mechanisms activate for failed requests"
      - "Circuit breakers may open if timeouts are excessive"
      - "System maintains functionality with degraded performance"
    
    safety_measures:
      - "Start with 200ms delay, increase gradually"
      - "Monitor end-to-end user experience"
      - "Immediate latency removal on abort"
      - "Fallback to direct service calls if needed"

# Experiment Execution Guidelines
execution_guidelines:
  preparation:
    - "Ensure all monitoring dashboards are active"
    - "Verify baseline metrics are within steady state"
    - "Confirm staging environment isolation"
    - "Prepare rollback procedures"
  
  during_experiment:
    - "Monitor metrics every 30 seconds"
    - "Log all observations and anomalies"
    - "Be ready to abort if safety conditions are breached"
    - "Capture screenshots of monitoring dashboards"
  
  post_experiment:
    - "Allow 5-10 minutes for system recovery"
    - "Verify return to steady state"
    - "Document lessons learned"
    - "Update monitoring or alerting if needed"

# Monitoring Stack
monitoring_setup:
  metrics_collection: "Prometheus (port 9467)"
  visualization: "Grafana dashboards"
  tracing: "Jaeger distributed tracing"
  logs: "Centralized logging with correlation IDs"
  alerts: "Automated alerts for abort conditions"